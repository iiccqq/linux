参考地址
https://clickhouse.tech/#quick-start
https://zhuanlan.zhihu.com/p/34669883


一、docker版本检验
启动clickhouse-server实例
docker run -d --name some-clickhouse-server --ulimit nofile=262144:262144 yandex/clickhouse-server
clickhouse-client连接
docker run -it --rm --link some-clickhouse-server:clickhouse-server yandex/clickhouse-client --host clickhouse-server

快速体验
CREATE TABLE ontime_local (FlightDate Date,Year UInt16) ENGINE = MergeTree(FlightDate, (Year, FlightDate), 8192);
insert into ontime_local (FlightDate,Year) values('2001-10-12',2001);
select count(*) from ontime_local;

集群版安装

基础环境准备
vi /etc/hosts
192.168.56.101   node1.clickhouse.com   node1
192.168.56.102   node2.clickhouse.com   node2
192.168.56.103   node3.clickhouse.com   node3

192.168.56.101 zk1.clickhouse.com   zk1
192.168.56.102 zk2.clickhouse.com   zk2
192.168.56.103 zk3.clickhouse.com   zk3


sudo sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/selinux/config
setenforce 0
sudo grep SELINUX=disabled /etc/selinux/config

sudo yum install yum-utils
sudo rpm --import https://repo.clickhouse.tech/CLICKHOUSE-KEY.GPG
sudo yum-config-manager --add-repo https://repo.clickhouse.tech/rpm/clickhouse.repo
sudo yum install clickhouse-server clickhouse-client

安装完后
确保以下配置已经更改
cat /etc/security/limits.d/clickhouse.conf
clickhouse      soft    nofile  262144
clickhouse      hard    nofile  262144

新版本在centos7上
vi /etc/systemd/system/clickhouse-server.service
ExecStart=/usr/bin/clickhouse-server --config=/data/clickhouse/config.xml --pid-file=/data/clickhouse/clickhouse-server.pid

<!--
/etc/rc.d/init.d/clickhouse-server 应该不需要改
vi /etc/rc.d/init.d/clickhouse-server
CLICKHOUSE_LOGDIR=/data/clickhouse/log
CLICKHOUSE_CONFIG=/data/clickhouse/config.xml
CLICKHOUSE_DATADIR=/data/clickhouse/data
然后注释掉原来的对应项
-->

 mkdir -p /data/clickhouse
 mkdir -p /data/clickhouse/log
 mkdir -p /data/clickhouse/tmp
 mkdir -p /data/clickhouse/data
 
 cp /etc/clickhouse-server/config.xml /data/clickhouse/
 cp /etc/clickhouse-server/users.xml /data/clickhouse/
 chown -R clickhouse:clickhouse /data/clickhouse
 
 vi /data/clickhouse/config.xml
 修改以下配置，参考以下，可以在原有的配置上修改，主要是涉及路径和 log，errorlog，listen_host、interserver_http_host、include_from、path、tmp_path
 需要注意interserver_http_host配置每个主机都不同，其他配置保持一致，建议使用域名映射，方便数据入库的时候轮训写入各节点均衡数据。
 <?xml version="1.0"?>
<yandex>
    <logger>
        <level>trace</level>
        <log>/data/clickhouse/log/server.log</log>
        <errorlog>/data/clickhouse/log/error.log</errorlog>
        <size>1000M</size>
        <count>10</count>
    </logger>

    <!-- For HTTPS over native protocol. -->
    <!--
    <https_port>8443</https_port>
    -->
    <http_port>8123</http_port>
    <tcp_port>9000</tcp_port>

    <!-- Port for communication between replicas. Used for data exchange. -->
    <interserver_http_port>9009</interserver_http_port>

    <!-- 本机域名 -->
    <interserver_http_host>node1.clickhouse.com</interserver_http_host>

    <!-- 监听IP -->
    <listen_host>0.0.0.0</listen_host>

    <!-- 最大连接数 -->
    <max_connections>64</max_connections>

    <!-- 没搞懂的参数 -->
    <keep_alive_timeout>3</keep_alive_timeout>

    <!-- 最大并发查询数 -->
    <max_concurrent_queries>16</max_concurrent_queries>

    <!-- 单位是B -->
    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
    <mark_cache_size>10737418240</mark_cache_size>

    <!-- 存储路径 -->
    <path>/data/clickhouse/data</path>
    <tmp_path>/data/clickhouse/tmp/</tmp_path>

    <!-- user配置 -->
    <users_config>users.xml</users_config>

    <default_profile>default</default_profile>

    <log_queries>1</log_queries>

    <default_database>default</default_database>

     <!-- Configuration of clusters that could be used in Distributed tables.
         https://clickhouse.yandex/docs/en/table_engines/distributed/
      -->
    <remote_servers incl="clickhouse_remote_servers" />

    <zookeeper incl="zookeeper-servers" optional="true" />

     <!-- Substitutions for parameters of replicated tables.
          Optional. If you don't use replicated tables, you could omit that.
         See https://clickhouse.yandex/docs/en/table_engines/replication/#creating-replicated-tables
      -->
    <macros incl="macros" optional="true" />

     <!-- Reloading interval for embedded dictionaries, in seconds. Default: 3600. -->
    <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>

    <!-- 控制大表的删除 -->
    <max_table_size_to_drop>0</max_table_size_to_drop>

    <!-- 集群配置文件 -->
    <include_from>/data/clickhouse/metrika.xml</include_from>
</yandex>


vi /data/clickhouse/metrika.xml
<?xml version="1.0"?>
<yandex>
<!-- 集群配置 -->
<clickhouse_remote_servers>
    <bip_ck_cluster>
        <!-- 数据分片1  -->
        <shard>
            <internal_replication>false</internal_replication>
            <replica>
                <host>node1.clickhouse.com</host>
                <port>9000</port>
                <user>default</user>
                <password>Q4jqoxLj</password>
            </replica>
        </shard>
        <!-- 数据分片2  -->
        <shard>
            <internal_replication>false</internal_replication>
            <replica>
                <host>node2.clickhouse.com</host>
                <port>9000</port>
                <user>default</user>
                <password>Q4jqoxLj</password>
            </replica>
        </shard>
        <!-- 数据分片3  -->
        <shard>
            <internal_replication>false</internal_replication>
            <replica>
                <host>node3.clickhouse.com</host>
                <port>9000</port>
                <user>default</user>
                <password>Q4jqoxLj</password>
            </replica>
        </shard>
    </bip_ck_cluster>
</clickhouse_remote_servers>
<!-- 本节点副本名称，创建复制表时有用，每个节点不同，整个集群唯一，建议使用主机名） -->
<macros>
    <replica>node1</replica>
</macros>
<!-- 监听网络 -->
<networks>
   <ip>::/0</ip>
</networks>
<!-- ZK集群  -->
<zookeeper-servers>
  <node index="1">
    <host>zk1.clickhouse.com</host>
    <port>2181</port>
  </node>
  <node index="2">
    <host>zk2.clickhouse.com</host>
    <port>2181</port>
  </node>
  <node index="3">
    <host>zk3.clickhouse.com</host>
    <port>2181</port>
  </node>
</zookeeper-servers>
<!-- 数据压缩算法  -->
<clickhouse_compression>
<case>
  <min_part_size>10000000000</min_part_size>
  <min_part_size_ratio>0.01</min_part_size_ratio>
  <method>lz4</method>
</case>
</clickhouse_compression>
</yandex>


vi /data/clickhouse/users.xml 


<?xml version="1.0"?>
<yandex>
    <profiles>
        <!-- 读写用户设置  -->
        <default>
            <max_memory_usage>10000000000</max_memory_usage>
            <use_uncompressed_cache>0</use_uncompressed_cache>
            <load_balancing>random</load_balancing>
        </default>
        <!-- 只写用户设置  -->
        <readonly>
            <max_memory_usage>10000000000</max_memory_usage>
            <use_uncompressed_cache>0</use_uncompressed_cache>
            <load_balancing>random</load_balancing>
            <readonly>1</readonly>
        </readonly>
    </profiles>
    <!-- 配额  -->
    <quotas>
        <!-- Name of quota. -->
        <default>
            <interval>
                <duration>3600</duration>
                <queries>0</queries>
                <errors>0</errors>
                <result_rows>0</result_rows>
                <read_rows>0</read_rows>
                <execution_time>0</execution_time>
            </interval>
        </default>
    </quotas>
    <users>
        <!-- 读写用户 Q4jqoxLj -->
        <default>
            <password_sha256_hex>c81541225f420acab020bc9b637ebd03e19f0f785c05888706983655f2614a40</password_sha256_hex>
            <networks incl="networks" replace="replace">
                <ip>::/0</ip>
            </networks>
            <profile>default</profile>
            <quota>default</quota>
        </default>
        <!-- 只读用户  -->
        <ck>
            <password_sha256_hex>c81541225f420acab020bc9b637ebd03e19f0f785c05888706983655f2614a40</password_sha256_hex>
            <networks incl="networks" replace="replace">
                <ip>::/0</ip>
            </networks>
            <profile>readonly</profile>
            <quota>default</quota>
        </ck>
    </users>
</yandex>


chown -R clickhouse:clickhouse /data/clickhouse

clickhouse新版本的需要以下启动，clickhouse老版本用service clickhouse-server start
systemctl start clickhouse-server


clickhouse-client -h 127.0.0.1 -d default -m -u default --password Q4jqoxLj
use system;
select * from clusters;
CREATE TABLE ontime_local (FlightDate Date,Year UInt16) ENGINE = MergeTree(FlightDate, (Year, FlightDate), 8192);
CREATE TABLE ontime_all AS ontime_local ENGINE = Distributed(bip_ck_cluster, default, ontime_local, rand());
insert into ontime_local (FlightDate,Year)values('2001-10-12',2001);
insert into ontime_local (FlightDate,Year)values('2002-10-12',2002);
insert into ontime_local (FlightDate,Year)values('2003-10-12',2003);
insert into ontime_all (FlightDate,Year)values('2003-10-12',2008);
select count(*) from ontime_all;


配置多磁盘
参考：
https://cloud.tencent.com/developer/article/1649377
https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/mergetree/
vi storage.xml
<yandex>
<storage_configuration>
     <default>
         <!--
             You can reserve some amount of free space
             on any disk (including default) by adding
             keep_free_space_bytes tag
         -->
         <keep_free_space_bytes>1024</keep_free_space_bytes>
      </default>
    <disks>
        <disk_sdc>
            <path>/data/sdc/clickhouse/data/</path>
        </disk_sdc>
        <disk_sdd>
            <path>/data/sdd/clickhouse/data/</path>
        </disk_sdd>
    </disks>
  <policies>
        <policy_in_order>
            <volumes>
                <vol1>
                    <disk>disk_sdc</disk>
                    <disk>disk_sdd</disk>
                </vol1>
            </volumes>
            <move_factor>0.2</move_factor>
        </policy_in_order>
    </policies>
</storage_configuration>
</yandex>

select * from system.disks;
SELECT
    name,
    path,
    formatReadableSize(free_space) AS free,
    formatReadableSize(total_space) AS total,
    formatReadableSize(keep_free_space) AS reserved
FROM system.disks;
select * from system.storage_policies;

CREATE TABLE sample2 (id UInt64) Engine=MergeTree 
ORDER BY id SETTINGS storage_policy = 'policy_in_order';

INSERT INTO sample2 SELECT * FROM numbers(1000000);

SELECT name, data_paths, metadata_path, storage_policy
FROM system.tables
WHERE name LIKE 'sample%'





