

官方文档：
http://hadoop.apache.org/docs/r2.9.0/hadoop-project-dist/hadoop-common/ClusterSetup.html


下载hadoop
wget http://apache.website-solution.net/hadoop/common/hadoop-2.9.0/hadoop-2.9.0.tar.gz
sudo yum install -y rsync

修改hosts
sudo vi /etc/hosts
192.168.56.101 NameNode
192.168.56.102 ResourceManager
192.168.56.103 Slave1
192.168.56.104 Slave2


环境变量
sudo vi  etc/hadoop/hadoop-env.sh 
export JAVA_HOME=/opt/jdk1.8.0_144


sudo vi /etc/profile.d/hadoop.sh

export HADOOP_HOME=/opt/hadoop-2.9.0
HADOOP_PREFIX=/opt/hadoop-2.9.0
export HADOOP_PREFIX
export HADOOP_CONF_DIR=/opt/hadoop-2.9.0/etc/hadoop
export HADOOP_YARN_HOME=/opt/hadoop-2.9.0
export PATH=$PATH:$HADOOP_PREFIX/bin

source /etc/profile

vi etc/hadoop/core-site.xml

 <property>
        <name>fs.defaultFS</name>
        <value>hdfs://NameNode:9000</value>
    </property>
    <property>
        <name>io.file.buffer.size</name>
        <value>131072</value>
    </property>
    

vi etc/hadoop/hdfs-site.xml


Configurations for NameNode:
Configurations for DataNode:

   
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/home/vagrant/namenodedir</value>
    </property>	
    
	 <property>
        <name>dfs.blocksize</name>
        <value>268435456</value>
    </property>
	 <property>
        <name>dfs.namenode.handler.count</name>
        <value>100</value>
    </property>	
	
	 <property>
        <name>dfs.datanode.data.dir</name>
        <value>/home/vagrant/datanodedir</value>
    </property>
	
	 mkdir -p /home/vagrant/namenodedir 
	 mkdir -p /home/vagrant/datanodedir 

Configurations for ResourceManager and NodeManager:
vi etc/hadoop/yarn-site.xml

    <property>
        <name>yarn.acl.enable</name>
        <value>false</value>
    </property>
	  <property>
        <name>yarn.admin.acl</name>
        <value>*</value>
    </property>
	  <property>
        <name>yarn.log-aggregation-enable</name>
        <value>false</value>
    </property>	
	  <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>ResourceManager</value>
    </property>
如果提示。。虚拟机内存小。可以增加以下配置
	<property>
    <name>yarn.nodemanager.vmem-check-enabled</name>
    <value>false</value>
</property>

	
  在NameNode和ResourceManager上执行
  $ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
  $ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
  $ chmod 0600 ~/.ssh/authorized_keys
  $	ssh-copy-id -i ~/.ssh/id_rsa.pub NameNode
  $	ssh-copy-id -i ~/.ssh/id_rsa.pub ResourceManager
  $	ssh-copy-id -i ~/.ssh/id_rsa.pub Slave1
  $	ssh-copy-id -i ~/.ssh/id_rsa.pub Slave2  
  
  在NameNode机器上运行：
	
	 [hdfs]$ $HADOOP_PREFIX/bin/hdfs namenode -format fc	 
	 [hdfs]$ $HADOOP_PREFIX/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs start namenode
	 [hdfs]$ $HADOOP_PREFIX/sbin/hadoop-daemons.sh --config $HADOOP_CONF_DIR --script hdfs start datanode
	 [hdfs]$ $HADOOP_PREFIX/sbin/start-dfs.sh
	 
  在ResourceManager机器上运行：
	[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR start resourcemanager
	[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemons.sh --config $HADOOP_CONF_DIR start nodemanager
	[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR start proxyserver
	[yarn]$ $HADOOP_PREFIX/sbin/start-yarn.sh
	[mapred]$ $HADOOP_PREFIX/sbin/mr-jobhistory-daemon.sh --config $HADOOP_CONF_DIR start historyserver
	
	
	[hdfs]$ $HADOOP_PREFIX/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs stop namenode
	[hdfs]$ $HADOOP_PREFIX/sbin/hadoop-daemons.sh --config $HADOOP_CONF_DIR --script hdfs stop datanode
	[hdfs]$ $HADOOP_PREFIX/sbin/stop-dfs.sh
	
	[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR stop resourcemanager
	[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemons.sh --config $HADOOP_CONF_DIR stop nodemanager
	[yarn]$ $HADOOP_PREFIX/sbin/stop-yarn.sh
	[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR stop proxyserver
	[mapred]$ $HADOOP_PREFIX/sbin/mr-jobhistory-daemon.sh --config $HADOOP_CONF_DIR stop historyserver
	
	查看日志位置：$HADOOP_PREFIX/logs下
	
	
增加slave的ip到配置
vi conf/hadoop/slaves

一、增加datanode
增加白名单 
增加节点配置
<property>
    <name>dfs.hosts</name>
    <value>/XXXXXXX/hadoop-2.7.1/etc/hadoop/hosts/datanode_hosts</value>
</property>
删除节点配置
<property>
    <name>dfs.hosts.exclude</name>
    <value>/XXXXXXX/hadoop-2.7.1/etc/hadoop/hosts/exclude_datanode_hosts</value>
</property>

/XXXXXXX/hadoop-2.7.1/etc/hadoop/hosts/datanode_hosts
每行放的主机名，是能ping的地址，每台机器上需要配置etc/host。


软件包及配置同步到增加的slave节点上
启动增加的datanode
sbin/hadoop-daemon.sh start datanode

更新节点
bin/hadoop dfsadmin -refreshNodes


bin/hadoop dfsadmin -report 


二、增加nodemanager

    <property>
        <name>yarn.resourcemanager.nodes.include-path</name>
        <value>/XXXXXXX/hadoop-2.7.1/etc/hadoop/hosts/mapred_hosts</value>
    </property>
    <property>
        <name>yarn.resourcemanager.nodes.exclude-path</name>
        <value>/XXXXXXX/hadoop-2.7.1/etc/hadoop/hosts/exclude_mapred_hosts</value>
    </property>

软件包及配置同步到增加的slave节点上
sbin/yarn-daemon.sh start nodemanager

集群负载均衡
bin/start-balancer.sh


常用操作：
        删除文件 
	hdfs dfs -rm -skipTrash /tmp/*
	hdfs dfs -rmr /tmp/*
	hdfs dfs -expunge
	
修改yarn的队列
 <property>
        <name>yarn.scheduler.fair.allocation.file</name>
        <value>/XXXX/hadoop-2.7.1/etc/hadoop/fair-scheduler.xml</value>
    </property>

fair-scheduler.xml配置队列内容后

yarn rmadmin -refreshQueues

开启远程调试
hadoop-2.7.1
vi etc/hadoop/hadoop-env.sh
增加以下内容
HADOOP_DEBUG_OPTS="-agentlib:jdwp=transport=dt_socket,server=y,"
# Command specific options appended to HADOOP_OPTS when specified
export HADOOP_NAMENODE_OPTS="${HADOOP_DEBUG_OPTS}suspend=n,address=9555 -Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} " # $HADOOP_NAMENODE_OPTS"
export HADOOP_DATANODE_OPTS="${HADOOP_DEBUG_OPTS}suspend=n,address=9552 -Dhadoop.security.logger=ERROR,RFAS " # $HADOOP_DATANODE_OPTS"



